
\begin{question}
Suppose we have splitted time series into training and test sets and estimated three different models. Which of the following statements is correct?
\begin{answerlist}
  \item Growing window cross-validation is better than the sliding window cross-validation if the process is stationary
  \item For sliding window cross-validation a selected window size should be as small as possible
  \item Approximate cross-validation by one step forward based on MAPE can be done using Akaike Information Criterion
  \item Sliding window cross-validation can be used on a small dataset
\end{answerlist}
\end{question}

\begin{solution}
\begin{answerlist}
  \item True.
  \item False. A short data sample increases the chance that your parameter estimates are imprecis
  \item False. This is true for RMSE based CV
  \item False. Either the number of observations for a training set or the number of CV-iterations will be small
\end{answerlist}
\end{solution}

